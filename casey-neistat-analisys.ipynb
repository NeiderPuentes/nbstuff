{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "import isodate\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlencode\n",
    "from slugify import slugify\n",
    "from pytube import YouTube\n",
    "\n",
    "if not os.path.exists(\"casey-neistat-analisys\"):\n",
    "    os.makedirs(\"casey-neistat-analisys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\" # Place your YT api key here\n",
    "assert api_key != \"\"\n",
    "channel_id = 'UCtinbF-Q-fVthA0qrFQTgXQ'\n",
    "\n",
    "playlists_parameters = {\n",
    "    'part': 'contentDetails',\n",
    "    'id': channel_id,\n",
    "    'key': api_key\n",
    "}\n",
    "\n",
    "categories_parameters = {\n",
    "    'part': 'snippet',\n",
    "    'regionCode': 'US',\n",
    "    'key': api_key\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    'key': api_key,\n",
    "    'part': 'snippet',\n",
    "    'type': 'video',\n",
    "    'channelId': channel_id,\n",
    "    'maxResults': 50,\n",
    "    'order': 'date'\n",
    "}\n",
    "max_pages = 100\n",
    "query_string = urlencode(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_categories_url = \"https://www.googleapis.com/youtube/v3/videoCategories?\" + urlencode(categories_parameters)\n",
    "r = requests.get(get_categories_url)\n",
    "result = json.loads(r.text)\n",
    "categoryId = []\n",
    "categoryNames = []\n",
    "for category in result['items']:\n",
    "    categoryId.append(int(category['id']))\n",
    "    categoryNames.append(category['snippet']['title'])\n",
    "categories_df = pd.DataFrame({'category': categoryId, 'name': categoryNames})\n",
    "categories_df.head()\n",
    "categories_df.to_csv(\"casey-neistat-analisys/categories_US.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_playlists_url = \"https://www.googleapis.com/youtube/v3/channels?\" + urlencode(playlists_parameters)\n",
    "r = requests.get(get_playlists_url)\n",
    "result = json.loads(r.text)\n",
    "\n",
    "playlist_id = result['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "print(playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "videos = []\n",
    "search_url = \"https://www.googleapis.com/youtube/v3/playlistItems?\"\n",
    "parameters['playlistId'] = playlist_id\n",
    "query_string = urlencode(parameters)\n",
    "pages = max_pages\n",
    "page_token = 'FIRST TIME!'\n",
    "while pages > 0 and len(page_token) > 0:\n",
    "    qurl = search_url + query_string\n",
    "    r = requests.get(search_url + query_string)\n",
    "    result = json.loads(r.text)\n",
    "    try:\n",
    "        page_token = result[\"nextPageToken\"]\n",
    "    except:\n",
    "        page_token = ''\n",
    "    parameters['pageToken'] = page_token\n",
    "    pages = pages - 1\n",
    "    videos.extend(result['items'])\n",
    "    count += len(result['items'])\n",
    "    query_string = urlencode(parameters)\n",
    "print(\"Done, found\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to dataframes\n",
    "ids = []\n",
    "pub = []\n",
    "titles = []\n",
    "for v in videos:\n",
    "    videoId = v['snippet']['resourceId']['videoId']\n",
    "    #print(json.dumps(v))\n",
    "    publishedDate = v['snippet']['publishedAt']\n",
    "    title =  v['snippet']['title']\n",
    "    ids.append(videoId)\n",
    "    pub.append(publishedDate)\n",
    "    titles.append(title)\n",
    "initial_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'published_at': pub,\n",
    "    'title': titles\n",
    "})\n",
    "initial_df['published_at'] = pd.to_datetime(initial_df['published_at'])\n",
    "initial_df.to_csv(\"casey-neistat-analisys/casey_initial.csv\", encoding='utf-8')\n",
    "print(initial_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(initial_df['id'].values)\n",
    "categories = []\n",
    "default_language = []\n",
    "durations = []\n",
    "license = []\n",
    "viewCounts = []\n",
    "likeCounts = []\n",
    "dislikeCounts = []\n",
    "favoriteCounts = []\n",
    "commentCounts = []\n",
    "a=True\n",
    "batch_size = 50\n",
    "i = 0\n",
    "video_details = \"https://www.googleapis.com/youtube/v3/videos?id=%s&part=snippet,statistics,contentDetails&key=%s\" \n",
    "while i < len(ids):\n",
    "    ids_to_query = ','.join(ids[i:i+batch_size])\n",
    "    q = video_details % (ids_to_query, api_key)\n",
    "    r = requests.get(q)\n",
    "    resultlist = json.loads(r.text)\n",
    "    for result in resultlist['items']:\n",
    "        snippet = result['snippet']\n",
    "        contentDetails = result['contentDetails']\n",
    "        statistics = result['statistics']\n",
    "\n",
    "        categories.append(snippet['categoryId'])\n",
    "        if 'defaultAudioLanguage' in snippet:\n",
    "            default_language.append(snippet['defaultAudioLanguage'])\n",
    "        else:\n",
    "            default_language.append('-')\n",
    "        durations.append(contentDetails['duration'])\n",
    "        license.append(contentDetails['licensedContent'])\n",
    "        viewCounts.append(statistics['viewCount'])\n",
    "        favoriteCounts.append(statistics['favoriteCount'])\n",
    "        likeCount = -1\n",
    "        dislikeCount = -1\n",
    "        commentCount = -1\n",
    "        if 'likeCount' in statistics:\n",
    "            likeCount = int(statistics['likeCount'])\n",
    "            dislikeCount = int(statistics['dislikeCount'])\n",
    "        if 'commentCount' in statistics:\n",
    "            commentCount = int(statistics['commentCount'])\n",
    "        likeCounts.append(likeCount)\n",
    "        dislikeCounts.append(dislikeCount)\n",
    "        commentCounts.append(commentCount)\n",
    "    \n",
    "    i += batch_size\n",
    "\n",
    "details_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'category':categories,\n",
    "    'language': default_language,\n",
    "    'duration': durations,\n",
    "    'license': license,\n",
    "    'views': viewCounts,\n",
    "    'likes': likeCounts,\n",
    "    'dislikes': dislikeCounts,\n",
    "    'favs': favoriteCounts,\n",
    "    'comments': commentCounts\n",
    "})\n",
    "\n",
    "details_df.to_csv(\"casey-neistat-analisys/casey_detailed.csv\", encoding='utf-8')\n",
    "print(details_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.read_csv(\"casey-neistat-analisys/casey_initial.csv\", index_col=0, \n",
    "                         parse_dates=['published_at'], na_values=[-1, ''])\n",
    "details_df = pd.read_csv(\"casey-neistat-analisys/casey_detailed.csv\", index_col=0, na_values=[-1, ''])\n",
    "\n",
    "\n",
    "initial_df = initial_df.drop_duplicates()\n",
    "details_df = details_df.drop_duplicates()\n",
    "details_df.duration = details_df.duration.apply(lambda iso: isodate.parse_duration(iso).total_seconds())\n",
    "\n",
    "complete_df = pd.merge(left=initial_df, right=details_df, on='id')\n",
    "complete_df.fillna(-1)\n",
    "complete_df.set_index('published_at', inplace=True)\n",
    "\n",
    "print(complete_df.tail())\n",
    "complete_df.to_csv(\"casey-neistat-analisys/casey_complete.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.read_csv(\"casey-neistat-analisys/casey_complete.csv\", parse_dates=['published_at'], index_col=0)\n",
    "complete_df = complete_df.tz_localize('UTC').tz_convert('US/Pacific')\n",
    "complete_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# When he didnt uploaded a vlog:\n",
    "vlog_start,vlog_end = '2015-03-24', '2016-11-19'\n",
    "daily_vlog_count = complete_df.loc[vlog_start:vlog_end,['views']].resample('D').count()\n",
    "daily_vlog_count.columns = ['videos']\n",
    "print(daily_vlog_count[daily_vlog_count['videos'] == 0])\n",
    "print(daily_vlog_count['videos']['2015'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
