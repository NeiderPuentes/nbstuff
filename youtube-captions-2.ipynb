{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlencode\n",
    "from slugify import slugify\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song = \"\"\"Ella existio solo en un sueño \n",
    "el es un poema que el poeta \n",
    "nunca escribió \n",
    "y en la eternidad los dos \n",
    "unieron sus almas para darle vida \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "spanish_stopwords = set(list(punctuation)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning song\n",
    "song_wo_stopwords = [word.lower() for word in word_tokenize(song) if word.lower() not in spanish_stopwords]\n",
    "print(song_wo_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load words:\n",
    "candidates = {}\n",
    "\n",
    "for w in song_wo_stopwords:\n",
    "    candidates[w] = []\n",
    "    \n",
    "directory = 'youtube-captions/captions'\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\"json\"):\n",
    "        with open(join(directory, file), 'r') as captions_file:\n",
    "            video = json.load(captions_file)\n",
    "            captions = video['captions_parsed']\n",
    "            for caption in captions:\n",
    "                if caption['content'] == None:\n",
    "                    continue\n",
    "                tokenized = word_tokenize(caption['content'])\n",
    "                for w1 in tokenized:\n",
    "                    if w1.lower() in candidates:\n",
    "                        caption['id'] = video['id']\n",
    "                        caption['count'] = len(tokenized)\n",
    "                        candidates[w1.lower()].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.read_csv(\"youtube-captions/complete.csv\", index_col=0,parse_dates=['published_at'])\n",
    "print(complete_df.info())\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start_to_time(s: float):\n",
    "    seconds = float(s) / 60\n",
    "    ceil_seconds = math.floor(seconds)\n",
    "    minutes = ceil_seconds\n",
    "    seconds = round((seconds - ceil_seconds) * 60)\n",
    "    return str(minutes) +\"m\" + str(seconds)+ \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "video_url = \"http://youtube.com/watch?v=%s&t=%s\"\n",
    "for candidate_key in candidates:\n",
    "    print(candidate_key)\n",
    "    if len(candidates[candidate_key]) == 0:\n",
    "        continue\n",
    "    candidates[candidate_key].sort(key=lambda x: x['count'], reverse=True)\n",
    "    for c in candidates[candidate_key][:4]:\n",
    "        tokenized = word_tokenize(c['content'])\n",
    "        word_count = len(tokenized)\n",
    "        duration, start = float(c['duration']), float(c['start'])\n",
    "        word_duration = word_count / duration\n",
    "        word_location = tokenized.index(candidate_key)\n",
    "        tentative_word_start = (start + word_location * word_duration) - 1\n",
    "        print(video_url % (c['id'], start_to_time(tentative_word_start)))\n",
    "#        print(word_duration)\n",
    "#        print(video_url % (c['id'], start_to_time(text['start'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
